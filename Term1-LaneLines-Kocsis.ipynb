{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video solidYellowLeft_OUT.mp4\n",
      "[MoviePy] Writing video solidYellowLeft_OUT.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:24<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: solidYellowLeft_OUT.mp4 \n",
      "\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "##videos\n",
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "folder = \"test_images/\"\n",
    "images = os.listdir(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Converts to Grayscale. returns a grayscale image\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def color_dropout(image): \n",
    "    # Grab the x and y size and make a copy of the image\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    color_select = np.copy(image)\n",
    "\n",
    "    # Define color selection criteria\n",
    "    ###### MODIFY THESE VARIABLES TO MAKE YOUR COLOR SELECTION\n",
    "    red_threshold = 150\n",
    "    green_threshold = 150\n",
    "    blue_threshold = 150\n",
    "    ######\n",
    "\n",
    "    rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "    # Do a boolean or with the \"|\" character to identify\n",
    "    # pixels below the thresholds\n",
    "    thresholds = (image[:,:,0] < rgb_threshold[0]) \\\n",
    "                | (image[:,:,1] < rgb_threshold[1]) \\\n",
    "                | (image[:,:,2] < rgb_threshold[2])\n",
    "    color_select[thresholds] = [0,0,0]    \n",
    "    return color_select\n",
    "    \n",
    "\n",
    "#define the mask for the image. Returns a masked image\n",
    "def region_of_interest(img, vertices):\n",
    "\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "##perform the Gaussian conversion. Returns an image\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "##performs canny edge detection. Returns an image\n",
    "def cannyEdges(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "\n",
    "##Uses Hough space to determine lines and draw them on the image.  Returns an image with 1 right and 1 left line\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)   \n",
    "    draw_lines(line_img, lines)\n",
    "    #draw_hough_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "#used for testing to see where the lines are found at. \n",
    "def draw_hough_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "#Draws the actual lines on the image\n",
    "#returns an image with one line for each the left and right sides.\n",
    "def draw_lines(img, lines):\n",
    "    #determine the slope of each line.\n",
    "    linesAndSlopeList = determine_slope(lines) \n",
    "    topOfMask = img.shape[0] * .60\n",
    "    #Noe we need to split the lines into the left and right slope\n",
    "    leftLinesList = []\n",
    "    rightLinesList = []\n",
    "    #now we have an array with coordinates and slope\n",
    "    if linesAndSlopeList is not None:\n",
    "        for i in linesAndSlopeList:\n",
    "            try:             \n",
    "                if i[4]>=0:\n",
    "                    rightLinesList.append(i)\n",
    "                else:\n",
    "                    leftLinesList.append(i)\n",
    "            except IndexError:\n",
    "                continue\n",
    "    \n",
    "    newMaskColor = [51, 51, 255]  \n",
    "    thickness=10 \n",
    "    imshape = img.shape\n",
    "    \"\"\"\n",
    "    Here is where we will see if there are any lines at all. \n",
    "    if we dont have anything in the list len(list) == 0, then use the previous lines.\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    if (len(leftLinesList) == 0 ):\n",
    "        cv2.line(img, (int(previousLeftLineList[0][0]), int(previousLeftLineList[0][1])), (int(previousLeftLineList[0][2]), int(previousLeftLineList[0][3])), newMaskColor, thickness)\n",
    "    elif len(leftLinesList) > 0 :\n",
    "        #print(leftLinesList)\n",
    "        leftLinesAvgList = determine_lines_within_average_slope(leftLinesList)\n",
    "        #print(leftLinesAvgList)\n",
    "        averageX = (np.average(leftLinesAvgList, axis=0)[0]+np.average(leftLinesAvgList, axis=0)[2])/2\n",
    "        averageY = (np.average(leftLinesAvgList, axis=0)[1]+np.average(leftLinesAvgList, axis=0)[3])/2 \n",
    "        averageSlopeLeft = np.average(leftLinesAvgList, axis=0)[4]\n",
    "        newLineLeft = extrapolate_lines(averageX, averageY, averageSlopeLeft, imshape[0], topOfMask + 25)\n",
    "        previousLeftLineList.clear()\n",
    "        previousLeftLineList.append(newLineLeft)\n",
    "        cv2.line(img, (int(newLineLeft[0]), int(newLineLeft[1])), (int(newLineLeft[2]), int(newLineLeft[3])), newMaskColor, thickness)\n",
    "    \n",
    "    if (len(rightLinesList) == 0 & len(previousRightLineList) > 0):\n",
    "        cv2.line(img, (int(previousRightLineList[0][0]), int(previousRightLineList[0][1])), (int(previousRightLineList[0][2]), int(previousRightLineList[0][3])), newMaskColor, thickness)\n",
    "        \n",
    "    elif len(rightLinesList) > 0 :\n",
    "        rightLinesAvgList = determine_lines_within_average_slope(rightLinesList)\n",
    "        #print(\"AverageList:\", rightLinesAvgList)\n",
    "        averageX = (np.average(rightLinesAvgList, axis=0)[0]+np.average(rightLinesAvgList, axis=0)[2])/2\n",
    "        averageY = (np.average(rightLinesAvgList, axis=0)[1]+np.average(rightLinesAvgList, axis=0)[3])/2 \n",
    "        averageSlopeRight = np.average(rightLinesAvgList, axis=0)[4]\n",
    "        newLineRight = extrapolate_lines(averageX, averageY, averageSlopeRight, imshape[0], topOfMask + 25)\n",
    "        previousRightLineList.clear()\n",
    "        previousRightLineList.append(newLineRight)\n",
    "        cv2.line(img, (int(newLineRight[0]), int(newLineRight[1])), (int(newLineRight[2]), int(newLineRight[3])), newMaskColor, thickness)\n",
    "\n",
    "\n",
    "        \n",
    "#lines from the hough transformation do not have the slope attached to them\n",
    "#returns an array of lines with slopes.\n",
    "def determine_slope(lines):\n",
    "    #get the slope for each line\n",
    "    #print(lines)\n",
    "    allLines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "                slopeLine = [x1,y1,x2,y2,slope]\n",
    "                allLines.append(slopeLine)\n",
    "        return allLines  \n",
    "\n",
    "\n",
    "\n",
    "#Finds the average slope of all the left or right lines\n",
    "# it then removes any which are above or below the threshold\n",
    "def determine_lines_within_average_slope(lines):    \n",
    "    returnLines = []\n",
    "    if len(lines) >= 1:\n",
    "        returnLines.clear()\n",
    "        linesToRemove = []\n",
    "        for i in lines:\n",
    "            if i[4] == 0 or i[0] == i[2] or i[1] == i[3]:\n",
    "                linesToRemove.append(i)\n",
    "           \n",
    "        for i in linesToRemove:\n",
    "            lines.remove(i)\n",
    "        #print(\"after removal\", lines)\n",
    "        averageSlope = np.mean(lines, axis = 0)[4]\n",
    "        #print(\"avg slope\", averageSlope)\n",
    "        #print(averageSlope)\n",
    "        lowThreshold = averageSlope - .3\n",
    "        highThreshold = averageSlope + .3        \n",
    "        #print(\"low\", lowThreshold)\n",
    "        #print(\"high\", highThreshold)\n",
    "        for i in lines:\n",
    "            if i[4]>=lowThreshold and i[4] <= highThreshold:\n",
    "                returnLines.append(i)\n",
    "        return returnLines\n",
    "    else:\n",
    "        return returnLines\n",
    "#takes a partial line and extrapolates it out to the top and bottom of the ROI mask\n",
    "def extrapolate_lines(x, y, slope, bottomY, topY):\n",
    "    yIntercept = y - (slope * x)\n",
    "    topX = (topY - yIntercept)/slope\n",
    "    bottomX = (bottomY - yIntercept)/slope   \n",
    "    newLine = [int(topX), int(topY), int(bottomX), int(bottomY)]\n",
    "    return newLine\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "   \n",
    "def process_image(image):\n",
    "\n",
    "    return read_and_mark_image(image)\n",
    "\n",
    "def read_and_mark_image(image):\n",
    "    \n",
    "    originalImage = image\n",
    "    lowThreshold = 50\n",
    "    highThreshold = 100\n",
    "    topOfMask = 300\n",
    "    rho =5\n",
    "    theta = np.pi/180\n",
    "    threshold = 200\n",
    "    min_line_length = 100\n",
    "    max_line_gap = 1\n",
    "    \n",
    "    #1. Convert to grayscale\n",
    "    gray = grayscale(image)\n",
    "             \n",
    "            \n",
    "    #2: do a color dropout.\n",
    "   \n",
    "    \n",
    "    #dropImage = color_dropout(image)\n",
    "    #return dropImage\n",
    "    \n",
    "    blurImage = gaussian_blur(image, 3)\n",
    "    \n",
    "    #3: perform canny edge detection\n",
    "    lowThreshold = 50\n",
    "    highThreshold = 150\n",
    "    canny = cannyEdges(blurImage, lowThreshold, highThreshold)\n",
    "    \n",
    "    imshape = canny.shape\n",
    "    \n",
    "    topOfMask = image.shape[0] * .6\n",
    "    maskTopLeftX = (image.shape[1] / 2) - (image.shape[1] * .05)\n",
    "    maskTopRightX = (image.shape[1] / 2) + (image.shape[1] * .05)\n",
    "    MaskBottomLeftX = image.shape[1] * .15\n",
    "    MaskBottomRightX = image.shape[1] * .95    \n",
    "    #4: apply the image mask \n",
    "    #vertices = np.array([[(115,imshape[0]),(470, topOfMask), (500,topOfMask), (900,imshape[0])]], dtype=np.int32)\n",
    "    vertices = np.array([[(MaskBottomLeftX, imshape[0]),(maskTopLeftX, topOfMask), (maskTopRightX, topOfMask), (MaskBottomRightX, imshape[0])]], dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    maskedImage = region_of_interest(canny, vertices)\n",
    "    #return maskedImage\n",
    "    #5 Perform the Hough Transfer, \n",
    "    rho = 5\n",
    "    theta = np.pi/180\n",
    "    threshold = 100\n",
    "    min_line_length = 10\n",
    "    max_line_gap = 1\n",
    "    houghImage = hough_lines(maskedImage, rho, theta, threshold, min_line_length, max_line_gap )   \n",
    "    \n",
    "    finalImage =  weighted_img(houghImage, originalImage)\n",
    "    \n",
    "    return finalImage\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "setting some variables here to deal with different resolution images... Prob dont have to do this in real life but I like one\n",
    "code base to run for everything.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "previousLeftLineList = []\n",
    "previousLeftLineList.append([0,0,0,0])\n",
    "previousRightLineList = []\n",
    "previousRightLineList.append([0,0,0,0])\n",
    "allLines = []\n",
    "\n",
    "\n",
    "imagesTest = False\n",
    "\n",
    "if imagesTest == True:    \n",
    "    for imageFile in images:            \n",
    "        image = mpimg.imread(folder + imageFile)\n",
    "        displayImage = read_and_mark_image(image)\n",
    "        plt.figure()\n",
    "        plt.imshow(displayImage, cmap='Greys_r')\n",
    "        plt.imshow(displayImage)\n",
    "        #filename, ext = os.path.splitext(imageFile)\n",
    "        #new_filename = os.path.join(folder, filename + \"_out\" + ext)\n",
    "        #mpimg.imsave(new_filename, displayImage, cmap='Greys_r')\n",
    "\n",
    "\n",
    "else:\n",
    "        \n",
    "    output = 'solidYellowLeft_OUT.mp4'\n",
    "    clip1 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "    clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "    %time clip.write_videofile(output, audio=False)\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection:\n",
    "This was my first time using Python, and it was quite a challenge.  I do a lot of .NET development, and I had to give up a lot of the tools I use, such as being able to step through the code and see how variables are actually being manipulated.  Python was also very confusing as variables are never directly instantiated as a type.  Meaning I could take a variable named \"Joe\" and make it a string, then an int, and then finally a list.  There was a lot of time spent printing out variables to see what I was actually working with.\n",
    "\n",
    "Some of the challenges I dealt with were just dealing with the basic Python syntax.  Most of the code I had planned out had to be rewritten due to various errors and access issues (making class variables). I also had to deal with images of varying sizes, which caused me to rewrite my ROI mask to use percentages instead of fixed pixels.  This allowed it to scale properly no matter what image size i used.  I can image this would not be an issue in a real world application since the picture will be a fixed width.\n",
    "\n",
    "Now on to the project itself. I made my pipeline (read_and_mark_images()) and went through the basic steps I was taught in class.  Perform the gray scale conversion, gaussian smoothing, canny edge detection, and finally a weighted image returned to the user.\n",
    "\n",
    "In order to find the lane lines, I did a few things.  First I split all the lines according to if the slope was + or 1, which gave me the left and right lines.  I then took the lines and determined an average slope for them, and removed all outliers which werent within a specific variance (.3).  Once I had the outliers removed, i had to determine if there were any lines actually in the list.  If there were, then I took the average coordinates and slope of the lines, and used a function extrapolate_lines() to create a full line. This method took the average coordinates and slope and used them to find the X coordinates for the top of the mask and the bottom of the image.  These were all we needed to find, since the Y coordinates came from the mask and the image itself.  A few times I ran into an issue where there were no lines identified.  For these circumstances I used the lines I previously found and drew them on the image until a new set of coordinates were found.\n",
    "\n",
    "For the extrapolate lines, I decided to use the averages and only draw one line for the left and one for the right.  I figured this would be much faster when it came to rendering the video. \n",
    "\n",
    "The pipeline seemed pretty smooth and there wasnt an extremely long time to render the video. however when trying it on the extra challenge video, there were a few areas where I missed the lines.  I also noticed the slopes I found were around .67 (- or +) so I am curious if this would be a good median threshold to use when determining if the lines i found are the lane lines or another random line. \n",
    "\n",
    "Overall, I found this to be a rather challenging project and I was very excited to complete it!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
